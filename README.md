# Tokyo Olympic Azure Data Engineering Project

## Overview
This project focuses on building a comprehensive data engineering pipeline for the Tokyo Olympic Games,

## Technologies Used
- **Azure Data Lake Gen2**: Storage for raw and processed data.
- **Azure Data Factory**: Orchestration and automation of data workflows.
- **Azure Databricks**: Advanced analytics and data transformation.
- **Azure Synapse Analytics**: Data warehousing and analytics.

## Project Structure
1. **Data Ingestion**: Raw data from various sources is ingested into Data Lake Gen2.
2. **ETL Pipeline**: Data is transformed and processed using Azure Data Factory and Databricks.
3. **Data Storage**: Processed data is stored in Azure Synapse Analytics for further analysis.
4. **Data Analysis**: Advanced analytics are performed using Databricks and visualizations are generated.


## Setup Instructions
1. **Azure Account**: Ensure you have an active Azure account.
2. **Azure Resources**: Create the necessary Azure resources - Data Lake Gen2, Data Factory, Databricks, and Synapse Analytics.
3. **Configuration**: Update configuration files with your Azure credentials and project-specific details.
4. **Run Pipelines**: Execute Data Factory pipelines for ETL, monitor Databricks jobs, and utilize Synapse Analytics for analytics.

## Usage
- Follow the documentation provided in the `docs` directory for detailed instructions on setting up, running, and maintaining the project.
- For any issues or inquiries, refer to the `Issues` section in this repository.
